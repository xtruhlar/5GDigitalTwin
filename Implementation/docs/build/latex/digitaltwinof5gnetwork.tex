%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}

\PassOptionsToPackage{booktabs}{sphinx}
\PassOptionsToPackage{colorrows}{sphinx}

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{tgtermes}
\usepackage{tgheros}
\renewcommand{\ttdefault}{txtt}



\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=auto}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\contentsname}{Getting Started}}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}



\title{Digital Twin of 5G Network}
\date{May 06, 2025}
\release{1.0}
\author{David Truhlar}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\ifdefined\shorthandoff
  \ifnum\catcode`\=\string=\active\shorthandoff{=}\fi
  \ifnum\catcode`\"=\active\shorthandoff{"}\fi
\fi

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


\sphinxstepscope


\chapter{Getting Started}
\label{\detokenize{getting_started:getting-started}}\label{\detokenize{getting_started::doc}}
\sphinxAtStartPar
Welcome to the documentation for the \sphinxstylestrong{Digital Twin of a 5G Network} developed as part of a bachelor thesis at the Slovak University of Technology.
This section will guide you through setting up, running, and extending the digital twin environment.


\section{Overview}
\label{\detokenize{getting_started:overview}}
\sphinxAtStartPar
This project simulates and analyzes 5G network behavior by integrating the following components:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Open5GS} \textendash{} a full 5G core implementation.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{UERANSIM} \textendash{} emulation of multiple UE and gNBs.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Prometheus \& Grafana} \textendash{} monitoring and visualization.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{LSTM models} \textendash{} classification of network behavior using deep learning.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Sphinx documentation} \textendash{} modular API docs.

\end{itemize}


\section{Prerequisites}
\label{\detokenize{getting_started:prerequisites}}
\sphinxAtStartPar
Before running the project, ensure you have:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Docker \& Docker Compose

\item {} 
\sphinxAtStartPar
Python 3.9+ and \sphinxtitleref{venv}

\item {} 
\sphinxAtStartPar
Git

\item {} 
\sphinxAtStartPar
At least 16 GB RAM (recommended for full stack simulation)

\end{itemize}

\sphinxstepscope


\chapter{Installation Guide}
\label{\detokenize{installation:installation-guide}}\label{\detokenize{installation::doc}}
\sphinxAtStartPar
First, ensure you have the following prerequisites installed:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Docker and Docker Compose
Python 3.9+ and `venv`
Git
\end{sphinxVerbatim}

\sphinxAtStartPar
Second, clone the repository:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
git\PYG{+w}{ }clone\PYG{+w}{ }https://github.com/xtruhlar/5GDigitalTwin.git
\PYG{n+nb}{cd}\PYG{+w}{ }5GDigitalTwin/Implementation
\end{sphinxVerbatim}

\sphinxAtStartPar
To build docker images

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{cd}\PYG{+w}{ }./open5gs/base
docker\PYG{+w}{ }build\PYG{+w}{ }\PYGZhy{}t\PYG{+w}{ }docker\PYGZus{}open5gs\PYG{+w}{ }.

\PYG{n+nb}{cd}\PYG{+w}{ }../ueransim
docker\PYG{+w}{ }build\PYG{+w}{ }\PYGZhy{}t\PYG{+w}{ }docker\PYGZus{}ueransim\PYG{+w}{ }.

\PYG{n+nb}{cd}\PYG{+w}{ }..
\end{sphinxVerbatim}

\sphinxAtStartPar
To set the environment variables

\begin{sphinxVerbatim}[commandchars=\\\{\}]
cp\PYG{+w}{ }.env.example\PYG{+w}{ }.env

\PYG{n+nb}{set}\PYG{+w}{ }\PYGZhy{}a
\PYG{n+nb}{source}\PYG{+w}{ }.env
\PYG{n+nb}{set}\PYG{+w}{ }+a
\end{sphinxVerbatim}

\sphinxAtStartPar
To run the project, navigate to \sphinxtitleref{Implementation/} and execute the following command

\begin{sphinxVerbatim}[commandchars=\\\{\}]
docker\PYG{+w}{ }compose\PYG{+w}{ }\PYGZhy{}f\PYG{+w}{ }deploy\PYGZhy{}all.yaml\PYG{+w}{ }up\PYG{+w}{ }\PYGZhy{}\PYGZhy{}build\PYG{+w}{ }\PYGZhy{}d
\end{sphinxVerbatim}

\sphinxAtStartPar
To add subscribers to Open5GS core, run the following commands

\begin{sphinxVerbatim}[commandchars=\\\{\}]
docker\PYG{+w}{ }\PYG{n+nb}{exec}\PYG{+w}{ }\PYGZhy{}it\PYG{+w}{ }mongo\PYG{+w}{ }mkdir\PYG{+w}{ }\PYGZhy{}p\PYG{+w}{ }/data/backup
ocker\PYG{+w}{ }cp\PYG{+w}{ }./open5gs/mongodb\PYGZus{}backup/open5gs\PYG{+w}{ }mongo:/data/backup/open5gs
docker\PYG{+w}{ }\PYG{n+nb}{exec}\PYG{+w}{ }\PYGZhy{}it\PYG{+w}{ }mongo\PYG{+w}{ }mongorestore\PYG{+w}{ }\PYGZhy{}\PYGZhy{}uri\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}mongodb://localhost:27017\PYGZdq{}}\PYG{+w}{ }\PYGZhy{}\PYGZhy{}db\PYG{+w}{ }open5gs\PYG{+w}{ }/data/backup/open5gs
\end{sphinxVerbatim}

\sphinxAtStartPar
To ensure everything works properly, open \sphinxurl{http://localhost:9999/} in your browser and login using credentials:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Username}\PYG{p}{:} \PYG{n}{admin}
\PYG{n}{Password}\PYG{p}{:} \PYG{l+m+mi}{1423}
\end{sphinxVerbatim}

\sphinxAtStartPar
To connect UERANSIM gNB to Open5GS, run the following command

\begin{sphinxVerbatim}[commandchars=\\\{\}]
docker\PYG{+w}{ }compose\PYG{+w}{ }\PYGZhy{}f\PYG{+w}{ }nr\PYGZhy{}gnb.yaml\PYG{+w}{ }\PYGZhy{}p\PYG{+w}{ }gnodeb\PYG{+w}{ }up\PYG{+w}{ }\PYGZhy{}d\PYG{+w}{ }\PYG{o}{\PYGZam{}\PYGZam{}}\PYG{+w}{ }docker\PYG{+w}{ }container\PYG{+w}{ }attach\PYG{+w}{ }nr\PYGZus{}gnb
\end{sphinxVerbatim}

\sphinxAtStartPar
To connect UERANSIM UE to Open5GS, run the following command

\begin{sphinxVerbatim}[commandchars=\\\{\}]
docker\PYG{+w}{ }compose\PYG{+w}{ }\PYGZhy{}f\PYG{+w}{ }nr\PYGZhy{}ue.yaml\PYG{+w}{ }\PYGZhy{}p\PYG{+w}{ }ue\PYG{+w}{ }up\PYG{+w}{ }\PYGZhy{}d\PYG{+w}{ }\PYG{o}{\PYGZam{}\PYGZam{}}\PYG{+w}{ }docker\PYG{+w}{ }container\PYG{+w}{ }attach\PYG{+w}{ }ue
\end{sphinxVerbatim}

\sphinxAtStartPar
Then go to Grafana, open \sphinxurl{http://localhost:3000/} in your browser and login using credentials:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Username}\PYG{p}{:} \PYG{n}{open5gs}
\PYG{n}{Password}\PYG{p}{:} \PYG{n}{open5gs}
\end{sphinxVerbatim}

\sphinxAtStartPar
Open menu on the left, click on \sphinxtitleref{Dashboards}. Select \sphinxtitleref{Current state Dash} and you can see the current state of your 5G network.

\sphinxAtStartPar
Example:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=1.000\linewidth]{{dashboard}.png}
\caption{Grafana dashboard}\label{\detokenize{installation:id1}}\end{figure}

\sphinxstepscope


\chapter{Normal Surfing}
\label{\detokenize{uc1:module-uc1}}\label{\detokenize{uc1:normal-surfing}}\label{\detokenize{uc1::doc}}\index{module@\spxentry{module}!uc1@\spxentry{uc1}}\index{uc1@\spxentry{uc1}!module@\spxentry{module}}\index{run\_uc1() (in module uc1)@\spxentry{run\_uc1()}\spxextra{in module uc1}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{uc1:uc1.run_uc1}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{uc1.}}\sphinxbfcode{\sphinxupquote{run\_uc1}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Run UC1: Normal Surfing scenario.

\sphinxAtStartPar
Simulates user behavior with intermittent UE connectivity and randomized data downloads
to mimic typical mobile web browsing patterns.
\begin{description}
\sphinxlineitem{Scenario Summary}\begin{itemize}
\item {} 
\sphinxAtStartPar
Starts half of the UEs.

\item {} \begin{description}
\sphinxlineitem{UEs may}\begin{itemize}
\item {} 
\sphinxAtStartPar
download random chunks of data (5\textendash{}50MB),

\item {} 
\sphinxAtStartPar
randomly disconnect or reconnect during the session.

\end{itemize}

\end{description}

\item {} 
\sphinxAtStartPar
The scenario runs for a randomized session duration (60\textendash{}600 seconds).

\item {} 
\sphinxAtStartPar
Active UEs are defined in \sphinxtitleref{nr\sphinxhyphen{}ue\{i\}.yaml} Docker Compose files.

\item {} 
\sphinxAtStartPar
Writes the current UC label to \sphinxtitleref{data/current\_uc.txt}.

\end{itemize}

\sphinxlineitem{Args}
\sphinxAtStartPar
None

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}


\sphinxstepscope


\chapter{Video Streaming}
\label{\detokenize{uc2:module-uc2}}\label{\detokenize{uc2:video-streaming}}\label{\detokenize{uc2::doc}}\index{module@\spxentry{module}!uc2@\spxentry{uc2}}\index{uc2@\spxentry{uc2}!module@\spxentry{module}}\index{run\_uc2() (in module uc2)@\spxentry{run\_uc2()}\spxextra{in module uc2}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{uc2:uc2.run_uc2}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{uc2.}}\sphinxbfcode{\sphinxupquote{run\_uc2}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Run UC2: Video Streaming scenario.

\sphinxAtStartPar
Simulates a typical video streaming session where all UEs continuously receive data.
This scenario helps to evaluate throughput and session stability under constant load.
\begin{description}
\sphinxlineitem{Scenario Summary}\begin{itemize}
\item {} 
\sphinxAtStartPar
Starts 4 UEs using Docker Compose.

\item {} 
\sphinxAtStartPar
Each UE downloads 2MB of random data every second.

\item {} 
\sphinxAtStartPar
Streaming duration is randomized between 300 and 600 seconds.

\item {} 
\sphinxAtStartPar
The UC label is logged into ‘data/current\_uc.txt’.

\end{itemize}

\sphinxlineitem{Args}
\sphinxAtStartPar
None

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}


\sphinxstepscope


\chapter{Periodic Keep\sphinxhyphen{}Alive}
\label{\detokenize{uc3:module-uc3}}\label{\detokenize{uc3:periodic-keep-alive}}\label{\detokenize{uc3::doc}}\index{module@\spxentry{module}!uc3@\spxentry{uc3}}\index{uc3@\spxentry{uc3}!module@\spxentry{module}}\index{run\_uc3() (in module uc3)@\spxentry{run\_uc3()}\spxextra{in module uc3}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{uc3:uc3.run_uc3}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{uc3.}}\sphinxbfcode{\sphinxupquote{run\_uc3}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Run UC3: Periodic Keep\sphinxhyphen{}Alive scenario.

\sphinxAtStartPar
Simulates multiple UEs that periodically send HTTP requests (keep\sphinxhyphen{}alive pings) to a remote server.
This pattern reflects real\sphinxhyphen{}world background traffic in mobile applications (e.g. chat apps, weather updates).
\begin{description}
\sphinxlineitem{Scenario Summary}\begin{itemize}
\item {} 
\sphinxAtStartPar
Starts 4 UEs as containers using Docker Compose.

\item {} 
\sphinxAtStartPar
Each UE sends periodic HTTP GET requests (via \sphinxtitleref{curl}) to a predefined URL.

\item {} 
\sphinxAtStartPar
The interval between pings is randomized between 30\textendash{}35 seconds.

\item {} 
\sphinxAtStartPar
Simulation duration is randomly set between 300\textendash{}600 seconds.

\item {} 
\sphinxAtStartPar
Scenario type is logged into ‘data/current\_uc.txt’.

\end{itemize}

\sphinxlineitem{Args}
\sphinxAtStartPar
None

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}


\sphinxstepscope


\chapter{Short Burst Sessions}
\label{\detokenize{uc4:module-uc4}}\label{\detokenize{uc4:short-burst-sessions}}\label{\detokenize{uc4::doc}}\index{module@\spxentry{module}!uc4@\spxentry{uc4}}\index{uc4@\spxentry{uc4}!module@\spxentry{module}}\index{run\_uc4() (in module uc4)@\spxentry{run\_uc4()}\spxextra{in module uc4}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{uc4:uc4.run_uc4}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{uc4.}}\sphinxbfcode{\sphinxupquote{run\_uc4}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Run UC4: Short Burst Sessions scenario.

\sphinxAtStartPar
Simulates multiple UEs initiating brief data sessions at random intervals. This pattern mimics sporadic, high\sphinxhyphen{}frequency user actions
(e.g. short API requests, fast\sphinxhyphen{}loading web content) in mobile networks.
\begin{description}
\sphinxlineitem{Scenario Summary}\begin{itemize}
\item {} 
\sphinxAtStartPar
Randomly selects a UE out of 4 available.

\item {} 
\sphinxAtStartPar
Starts a short Docker container session for the selected UE.

\item {} 
\sphinxAtStartPar
Simulates a 2MB data transfer using \sphinxtitleref{dd} inside the container.

\item {} 
\sphinxAtStartPar
After 2\textendash{}4 seconds, the UE container is stopped.

\item {} 
\sphinxAtStartPar
Waits 3\textendash{}6 seconds and repeats until the scenario duration ends.

\item {} 
\sphinxAtStartPar
Marks current use case in ‘data/current\_uc.txt’.

\end{itemize}

\sphinxlineitem{Args}
\sphinxAtStartPar
None

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}


\sphinxstepscope


\chapter{Load Registration Anomaly}
\label{\detokenize{uc5:module-uc5}}\label{\detokenize{uc5:load-registration-anomaly}}\label{\detokenize{uc5::doc}}\index{module@\spxentry{module}!uc5@\spxentry{uc5}}\index{uc5@\spxentry{uc5}!module@\spxentry{module}}\index{run\_uc5() (in module uc5)@\spxentry{run\_uc5()}\spxextra{in module uc5}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{uc5:uc5.run_uc5}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{uc5.}}\sphinxbfcode{\sphinxupquote{run\_uc5}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Run UC5: Load Registration Anomaly scenario.

\sphinxAtStartPar
Simulates a stress event in the 5G network by concurrently connecting multiple UEs. This tests the network’s ability
to handle sudden, simultaneous registration attempts — a common anomaly in overloaded environments.
\begin{description}
\sphinxlineitem{Scenario Summary}\begin{itemize}
\item {} 
\sphinxAtStartPar
Starts 4 UE containers simultaneously using \sphinxtitleref{subprocess.Popen}.

\item {} 
\sphinxAtStartPar
Waits for all containers to fully initialize.

\item {} 
\sphinxAtStartPar
Holds all UE sessions active for a short time (5 seconds by default).

\item {} 
\sphinxAtStartPar
Stops all containers simultaneously after the wait period.

\item {} 
\sphinxAtStartPar
Logs scenario activity to ‘data/current\_uc.txt’.

\end{itemize}

\sphinxlineitem{Args}
\sphinxAtStartPar
None

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}


\sphinxstepscope


\chapter{Authentication Failure Alert}
\label{\detokenize{uc6:module-uc6}}\label{\detokenize{uc6:authentication-failure-alert}}\label{\detokenize{uc6::doc}}\index{module@\spxentry{module}!uc6@\spxentry{uc6}}\index{uc6@\spxentry{uc6}!module@\spxentry{module}}\index{run\_uc6() (in module uc6)@\spxentry{run\_uc6()}\spxextra{in module uc6}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{uc6:uc6.run_uc6}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{uc6.}}\sphinxbfcode{\sphinxupquote{run\_uc6}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Run UC6: Authentication Failure Alert scenario.

\sphinxAtStartPar
Simulates an authentication failure event in a 5G network by repeatedly starting a misconfigured UE (User Equipment)
that fails to register due to incorrect credentials or malformed configuration. This scenario is useful for testing
network response to repeated failed attempts and monitoring for anomaly detection mechanisms.
\begin{description}
\sphinxlineitem{Scenario Summary}\begin{itemize}
\item {} 
\sphinxAtStartPar
Launches a specially prepared UE (ID=100) which is expected to fail authentication.

\item {} 
\sphinxAtStartPar
Repeats the process a random number of times (3 to 6 retries).

\item {} 
\sphinxAtStartPar
Between each attempt, the UE is stopped and a random interval (5\textendash{}30 seconds) is observed.

\item {} 
\sphinxAtStartPar
Total scenario duration is also bounded by a global timeout (120\textendash{}300 seconds).

\item {} 
\sphinxAtStartPar
All events are logged to the console and scenario type is saved to \sphinxtitleref{data/current\_uc.txt}.

\end{itemize}

\sphinxlineitem{Args}
\sphinxAtStartPar
None

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}


\sphinxstepscope


\chapter{LSTM Model with Attention}
\label{\detokenize{lstm_attention_model:module-lstm_attention_model}}\label{\detokenize{lstm_attention_model:lstm-model-with-attention}}\label{\detokenize{lstm_attention_model::doc}}\index{module@\spxentry{module}!lstm\_attention\_model@\spxentry{lstm\_attention\_model}}\index{lstm\_attention\_model@\spxentry{lstm\_attention\_model}!module@\spxentry{module}}\index{AttentionLayer (class in lstm\_attention\_model)@\spxentry{AttentionLayer}\spxextra{class in lstm\_attention\_model}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_attention_model:lstm_attention_model.AttentionLayer}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{lstm\_attention\_model.}}\sphinxbfcode{\sphinxupquote{AttentionLayer}}}{\sphinxparam{\DUrole{o}{*}\DUrole{n}{args}}\sphinxparamcomma \sphinxparam{\DUrole{o}{**}\DUrole{n}{kwargs}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Layer}}

\sphinxAtStartPar
Custom attention layer compatible with LSTM outputs.
Outputs a weighted sum across the time dimension.

\sphinxAtStartPar
Source: \sphinxurl{https://www.geeksforgeeks.org/adding-attention-layer-to-a-bi-lstm/}?
\index{build() (lstm\_attention\_model.AttentionLayer method)@\spxentry{build()}\spxextra{lstm\_attention\_model.AttentionLayer method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_attention_model:lstm_attention_model.AttentionLayer.build}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{build}}}{\sphinxparam{\DUrole{n}{input\_shape}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Build the attention layer.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
input\_shape: Shape of the input tensor.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}

\index{call() (lstm\_attention\_model.AttentionLayer method)@\spxentry{call()}\spxextra{lstm\_attention\_model.AttentionLayer method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_attention_model:lstm_attention_model.AttentionLayer.call}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{call}}}{\sphinxparam{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Apply the attention mechanism to the input tensor.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
x: Input tensor of shape (batch\_size, timesteps, features).

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
output: Weighted sum of the input tensor across the time dimension.

\end{itemize}

\end{description}

\end{fulllineitems}

\index{compute\_output\_shape() (lstm\_attention\_model.AttentionLayer method)@\spxentry{compute\_output\_shape()}\spxextra{lstm\_attention\_model.AttentionLayer method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_attention_model:lstm_attention_model.AttentionLayer.compute_output_shape}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{compute\_output\_shape}}}{\sphinxparam{\DUrole{n}{input\_shape}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the output shape of the attention layer.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
input\_shape: Shape of the input tensor.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
output\_shape: Shape of the output tensor.

\end{itemize}

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{build\_attention\_model() (in module lstm\_attention\_model)@\spxentry{build\_attention\_model()}\spxextra{in module lstm\_attention\_model}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_attention_model:lstm_attention_model.build_attention_model}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{lstm\_attention\_model.}}\sphinxbfcode{\sphinxupquote{build\_attention\_model}}}{\sphinxparam{\DUrole{n}{input\_shape}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num\_classes}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Build and return an attention\sphinxhyphen{}based LSTM model.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
input\_shape: tuple, shape of the input data (timesteps, features)

\item {} 
\sphinxAtStartPar
num\_classes: int, number of output classes

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
Keras Model instance

\end{itemize}

\end{description}

\end{fulllineitems}

\index{train\_attention\_model() (in module lstm\_attention\_model)@\spxentry{train\_attention\_model()}\spxextra{in module lstm\_attention\_model}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_attention_model:lstm_attention_model.train_attention_model}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{lstm\_attention\_model.}}\sphinxbfcode{\sphinxupquote{train\_attention\_model}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
LSTM model with custom attention mechanism for multi\sphinxhyphen{}class classification
of time\sphinxhyphen{}series data.

\sphinxAtStartPar
This module defines a deep learning model using TensorFlow and Keras,
integrates a custom attention mechanism, and trains the model
on preprocessed input data with categorical labels.
\begin{description}
\sphinxlineitem{Expected data format:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Input: X\_train.npy, X\_test.npy (shape: {[}samples, 60, features{]})

\item {} 
\sphinxAtStartPar
Labels: y\_train.npy, y\_test.npy (categorical class indices)

\item {} 
\sphinxAtStartPar
Class weights: class\_weights.json

\end{itemize}

\end{description}

\sphinxAtStartPar
The trained model is saved as HDF5 and Keras formats.

\end{fulllineitems}


\sphinxstepscope


\chapter{LSTM BathNorm Model}
\label{\detokenize{lstm_bathnorm_model:module-lstm_bathnorm_model}}\label{\detokenize{lstm_bathnorm_model:lstm-bathnorm-model}}\label{\detokenize{lstm_bathnorm_model::doc}}\index{module@\spxentry{module}!lstm\_bathnorm\_model@\spxentry{lstm\_bathnorm\_model}}\index{lstm\_bathnorm\_model@\spxentry{lstm\_bathnorm\_model}!module@\spxentry{module}}\index{train\_batchnorm\_model() (in module lstm\_bathnorm\_model)@\spxentry{train\_batchnorm\_model()}\spxextra{in module lstm\_bathnorm\_model}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_bathnorm_model:lstm_bathnorm_model.train_batchnorm_model}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{lstm\_bathnorm\_model.}}\sphinxbfcode{\sphinxupquote{train\_batchnorm\_model}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
LSTM BatchNorm Model

\sphinxAtStartPar
This module defines a deep learning model using TensorFlow and Keras with Batch Normalization
for multi\sphinxhyphen{}class classification of time\sphinxhyphen{}series data.
\begin{description}
\sphinxlineitem{Expected data format:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Input: X\_train.npy, X\_test.npy (shape: {[}samples, 60, features{]})

\item {} 
\sphinxAtStartPar
Labels: y\_train.npy, y\_test.npy (categorical class indices)

\item {} 
\sphinxAtStartPar
Class weights: class\_weights.json

\end{itemize}

\end{description}

\sphinxAtStartPar
The trained model is saved as HDF5 and Keras formats.

\end{fulllineitems}


\sphinxstepscope


\chapter{LSTM Base Model}
\label{\detokenize{lstm_base_model:module-lstm_base_model}}\label{\detokenize{lstm_base_model:lstm-base-model}}\label{\detokenize{lstm_base_model::doc}}\index{module@\spxentry{module}!lstm\_base\_model@\spxentry{lstm\_base\_model}}\index{lstm\_base\_model@\spxentry{lstm\_base\_model}!module@\spxentry{module}}\index{build\_base\_model() (in module lstm\_base\_model)@\spxentry{build\_base\_model()}\spxextra{in module lstm\_base\_model}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_base_model:lstm_base_model.build_base_model}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{lstm\_base\_model.}}\sphinxbfcode{\sphinxupquote{build\_base\_model}}}{\sphinxparam{\DUrole{n}{X\_train}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_train}}\sphinxparamcomma \sphinxparam{\DUrole{n}{X\_test}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_test}}\sphinxparamcomma \sphinxparam{\DUrole{n}{class\_weight\_dict}}}{}
\pysigstopsignatures
\sphinxAtStartPar
LSTM Base Model for classification of network use case scenarios.

\sphinxAtStartPar
This script loads preprocessed training and testing data, defines and trains
a baseline LSTM model, evaluates its performance, and saves the final model
in HDF5 and Keras formats. Class balancing is handled using precomputed class weights.
\begin{description}
\sphinxlineitem{Usage}\begin{itemize}
\item {} 
\sphinxAtStartPar
This script is designed to be executed as a module. Use the function \sphinxtitleref{build\_base\_model()} to construct and optionally train the model.

\end{itemize}

\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
X\_train (numpy.ndarray): Preprocessed training data.

\item {} 
\sphinxAtStartPar
y\_train (numpy.ndarray): Labels for the training data.

\item {} 
\sphinxAtStartPar
X\_test (numpy.ndarray): Preprocessed testing data.

\item {} 
\sphinxAtStartPar
y\_test (numpy.ndarray): Labels for the testing data.

\item {} 
\sphinxAtStartPar
class\_weight\_dict (dict): Class weights for handling class imbalance.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
model (tensorflow.keras.Model): Trained LSTM model.

\end{itemize}

\end{description}

\end{fulllineitems}


\sphinxstepscope


\chapter{LSTM Robust Model}
\label{\detokenize{lstm_robust_model:module-lstm_robust_model}}\label{\detokenize{lstm_robust_model:lstm-robust-model}}\label{\detokenize{lstm_robust_model::doc}}\index{module@\spxentry{module}!lstm\_robust\_model@\spxentry{lstm\_robust\_model}}\index{lstm\_robust\_model@\spxentry{lstm\_robust\_model}!module@\spxentry{module}}\index{build\_robust\_model() (in module lstm\_robust\_model)@\spxentry{build\_robust\_model()}\spxextra{in module lstm\_robust\_model}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_robust_model:lstm_robust_model.build_robust_model}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{lstm\_robust\_model.}}\sphinxbfcode{\sphinxupquote{build\_robust\_model}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Trains a robust LSTM model and saves it to the \sphinxtitleref{trained\_models/} directory.
The model consists of 3 LSTM layers with varying dropout rates and 2 Dense layers.
It is designed for classifying UC classes based on preprocessed sequential inputs.
\begin{description}
\sphinxlineitem{Args}
\sphinxAtStartPar
None

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\sphinxAtStartPar
The function saves the trained model to the \sphinxtitleref{trained\_models/} directory and generates visualizations for the confusion matrix and training history.

\end{fulllineitems}


\sphinxstepscope


\chapter{Classify the real data using LSTM}
\label{\detokenize{lstm_results_real_data:module-lstm_results_real_data}}\label{\detokenize{lstm_results_real_data:classify-the-real-data-using-lstm}}\label{\detokenize{lstm_results_real_data::doc}}\index{module@\spxentry{module}!lstm\_results\_real\_data@\spxentry{lstm\_results\_real\_data}}\index{lstm\_results\_real\_data@\spxentry{lstm\_results\_real\_data}!module@\spxentry{module}}
\sphinxAtStartPar
Module for evaluating multiple LSTM models (base, robust, batchnorm, attention)
on real\sphinxhyphen{}world 5G network data, with the option to fine\sphinxhyphen{}tune the attention model.
\begin{description}
\sphinxlineitem{This script includes}\begin{itemize}
\item {} 
\sphinxAtStartPar
Definition of a custom attention layer,

\item {} 
\sphinxAtStartPar
Real\sphinxhyphen{}data class weight computation,

\item {} 
\sphinxAtStartPar
Sequence generation for LSTM input,

\item {} 
\sphinxAtStartPar
Model accuracy evaluation via classification report,

\item {} 
\sphinxAtStartPar
Optional fine\sphinxhyphen{}tuning of the attention\sphinxhyphen{}based LSTM model.

\end{itemize}

\end{description}
\index{AttentionLayer (class in lstm\_results\_real\_data)@\spxentry{AttentionLayer}\spxextra{class in lstm\_results\_real\_data}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_results_real_data:lstm_results_real_data.AttentionLayer}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{lstm\_results\_real\_data.}}\sphinxbfcode{\sphinxupquote{AttentionLayer}}}{\sphinxparam{\DUrole{o}{*}\DUrole{n}{args}}\sphinxparamcomma \sphinxparam{\DUrole{o}{**}\DUrole{n}{kwargs}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Layer}}

\sphinxAtStartPar
Custom attention layer compatible with LSTM outputs.
Outputs a weighted sum across the time dimension.

\sphinxAtStartPar
Source: \sphinxurl{https://www.geeksforgeeks.org/adding-attention-layer-to-a-bi-lstm/}?
\index{build() (lstm\_results\_real\_data.AttentionLayer method)@\spxentry{build()}\spxextra{lstm\_results\_real\_data.AttentionLayer method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_results_real_data:lstm_results_real_data.AttentionLayer.build}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{build}}}{\sphinxparam{\DUrole{n}{input\_shape}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Build the attention layer.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
input\_shape: Shape of the input tensor.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}

\index{call() (lstm\_results\_real\_data.AttentionLayer method)@\spxentry{call()}\spxextra{lstm\_results\_real\_data.AttentionLayer method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_results_real_data:lstm_results_real_data.AttentionLayer.call}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{call}}}{\sphinxparam{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Apply the attention mechanism to the input tensor.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
x: Input tensor of shape (batch\_size, timesteps, features).

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
output: Weighted sum of the input tensor across the time dimension.

\end{itemize}

\end{description}

\end{fulllineitems}

\index{compute\_output\_shape() (lstm\_results\_real\_data.AttentionLayer method)@\spxentry{compute\_output\_shape()}\spxextra{lstm\_results\_real\_data.AttentionLayer method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_results_real_data:lstm_results_real_data.AttentionLayer.compute_output_shape}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{compute\_output\_shape}}}{\sphinxparam{\DUrole{n}{input\_shape}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the output shape of the attention layer.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
input\_shape: Shape of the input tensor.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
output\_shape: Shape of the output tensor.

\end{itemize}

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{create\_sequences() (in module lstm\_results\_real\_data)@\spxentry{create\_sequences()}\spxextra{in module lstm\_results\_real\_data}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_results_real_data:lstm_results_real_data.create_sequences}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{lstm\_results\_real\_data.}}\sphinxbfcode{\sphinxupquote{create\_sequences}}}{\sphinxparam{\DUrole{n}{X}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y}}\sphinxparamcomma \sphinxparam{\DUrole{n}{seq\_len}\DUrole{o}{=}\DUrole{default_value}{60}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Converts flattened input arrays into sliding window sequences for LSTM input.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
X (np.ndarray): Input features of shape (samples, features).

\item {} 
\sphinxAtStartPar
y (np.ndarray): Target labels corresponding to input samples.

\item {} 
\sphinxAtStartPar
seq\_len (int): Length of each sequence window. Default is 60.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
tuple: (X\_seq, y\_seq) where X\_seq has shape (samples \sphinxhyphen{} seq\_len, seq\_len, features) and y\_seq has shape (samples \sphinxhyphen{} seq\_len,).

\end{itemize}

\end{description}

\end{fulllineitems}

\index{evaluate\_model() (in module lstm\_results\_real\_data)@\spxentry{evaluate\_model()}\spxextra{in module lstm\_results\_real\_data}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_results_real_data:lstm_results_real_data.evaluate_model}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{lstm\_results\_real\_data.}}\sphinxbfcode{\sphinxupquote{evaluate\_model}}}{\sphinxparam{\DUrole{n}{model}}\sphinxparamcomma \sphinxparam{\DUrole{n}{X\_seq}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_seq}}\sphinxparamcomma \sphinxparam{\DUrole{n}{name}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Evaluates a trained model on given sequential data and prints classification report.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
model (keras.Model): The trained Keras model to evaluate.

\item {} 
\sphinxAtStartPar
X\_seq (np.ndarray): Sequential input data (samples, seq\_len, features).

\item {} 
\sphinxAtStartPar
y\_seq (np.ndarray): True class labels.

\item {} 
\sphinxAtStartPar
name (str): Name of the model for display purposes.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}

\index{load\_and\_preprocess\_data() (in module lstm\_results\_real\_data)@\spxentry{load\_and\_preprocess\_data()}\spxextra{in module lstm\_results\_real\_data}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_results_real_data:lstm_results_real_data.load_and_preprocess_data}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{lstm\_results\_real\_data.}}\sphinxbfcode{\sphinxupquote{load\_and\_preprocess\_data}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Loads the real\sphinxhyphen{}world labeled dataset and applies categorical mappings.
\begin{description}
\sphinxlineitem{Args}
\sphinxAtStartPar
None

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
pd.DataFrame: Preprocessed dataset with mapped categorical columns and timestamps.

\end{itemize}

\end{description}

\end{fulllineitems}

\index{run\_evaluation\_and\_finetuning() (in module lstm\_results\_real\_data)@\spxentry{run\_evaluation\_and\_finetuning()}\spxextra{in module lstm\_results\_real\_data}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_results_real_data:lstm_results_real_data.run_evaluation_and_finetuning}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{lstm\_results\_real\_data.}}\sphinxbfcode{\sphinxupquote{run\_evaluation\_and\_finetuning}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Main function to evaluate four trained LSTM models and fine\sphinxhyphen{}tune the attention model
using real labeled data.
\begin{description}
\sphinxlineitem{Args}
\sphinxAtStartPar
None

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}


\sphinxstepscope


\chapter{Exploratory Data Analysis}
\label{\detokenize{eda:module-eda}}\label{\detokenize{eda:exploratory-data-analysis}}\label{\detokenize{eda::doc}}\index{module@\spxentry{module}!eda@\spxentry{eda}}\index{eda@\spxentry{eda}!module@\spxentry{module}}
\sphinxAtStartPar
EDA module for exploratory analysis of synthetic and real 5G network datasets.

\sphinxAtStartPar
This module contains functions to load data, preprocess it, visualize it,
and perform feature selection using multiple strategies including RF, RFE,
RFECV, SFS and permutation importance.

\sphinxAtStartPar
Functions in this module should be called explicitly from a main script or notebook.
\index{compute\_class\_weights() (in module eda)@\spxentry{compute\_class\_weights()}\spxextra{in module eda}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{eda:eda.compute_class_weights}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{eda.}}\sphinxbfcode{\sphinxupquote{compute\_class\_weights}}}{\sphinxparam{\DUrole{n}{y}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Compute class weights for imbalanced classes.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
y (pd.Series): Target variable.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
dict: Dictionary mapping class labels to their corresponding weights.

\end{itemize}

\end{description}

\end{fulllineitems}

\index{load\_dataset() (in module eda)@\spxentry{load\_dataset()}\spxextra{in module eda}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{eda:eda.load_dataset}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{eda.}}\sphinxbfcode{\sphinxupquote{load\_dataset}}}{\sphinxparam{\DUrole{n}{path}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Load dataset from CSV file.
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{DataFrame}}}

\end{description}\end{quote}
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
path (str): Path to the CSV file.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
pd.DataFrame: Loaded dataset.

\end{itemize}

\end{description}

\end{fulllineitems}

\index{load\_maps() (in module eda)@\spxentry{load\_maps()}\spxextra{in module eda}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{eda:eda.load_maps}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{eda.}}\sphinxbfcode{\sphinxupquote{load\_maps}}}{\sphinxparam{\DUrole{n}{log\_map\_path}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}./json/log\_map.json\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{app\_map\_path}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}./json/app\_map.json\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{uc\_map\_path}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}./json/uc\_map.json\textquotesingle{}}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Load mapping dictionaries from JSON files.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
log\_map\_path (str): Path to the log type mapping JSON file.

\item {} 
\sphinxAtStartPar
app\_map\_path (str): Path to the application mapping JSON file.

\item {} 
\sphinxAtStartPar
uc\_map\_path (str): Path to the use case mapping JSON file.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} \begin{description}
\sphinxlineitem{tuple: A tuple containing three dictionaries:}\begin{itemize}
\item {} 
\sphinxAtStartPar
log\_map (dict): Mapping of log types to integers.

\item {} 
\sphinxAtStartPar
app\_map (dict): Mapping of applications to integers.

\item {} 
\sphinxAtStartPar
uc\_map (dict): Mapping of use cases to integers.

\end{itemize}

\end{description}

\end{itemize}

\end{description}

\end{fulllineitems}

\index{permutation\_importance\_stable() (in module eda)@\spxentry{permutation\_importance\_stable()}\spxextra{in module eda}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{eda:eda.permutation_importance_stable}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{eda.}}\sphinxbfcode{\sphinxupquote{permutation\_importance\_stable}}}{\sphinxparam{\DUrole{n}{X}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y}}\sphinxparamcomma \sphinxparam{\DUrole{n}{selected\_features}}\sphinxparamcomma \sphinxparam{\DUrole{n}{n\_runs}\DUrole{o}{=}\DUrole{default_value}{10}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate stable permutation importances over multiple runs.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
X (pd.DataFrame): Feature matrix.

\item {} 
\sphinxAtStartPar
y (pd.Series): Target variable.

\item {} 
\sphinxAtStartPar
selected\_features (list): List of selected feature names.

\item {} 
\sphinxAtStartPar
n\_runs (int): Number of runs for stability.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
pd.DataFrame: DataFrame containing mean and std of importances.

\end{itemize}

\end{description}

\end{fulllineitems}

\index{preprocess\_data() (in module eda)@\spxentry{preprocess\_data()}\spxextra{in module eda}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{eda:eda.preprocess_data}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{eda.}}\sphinxbfcode{\sphinxupquote{preprocess\_data}}}{\sphinxparam{\DUrole{n}{df}}\sphinxparamcomma \sphinxparam{\DUrole{n}{log\_map}}\sphinxparamcomma \sphinxparam{\DUrole{n}{app\_map}}\sphinxparamcomma \sphinxparam{\DUrole{n}{uc\_map}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Preprocess dataset: fill NA, map strings to ints, scale numeric columns.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
df (pd.DataFrame): Input DataFrame to preprocess.

\item {} 
\sphinxAtStartPar
log\_map (dict): Mapping of log types to integers.

\item {} 
\sphinxAtStartPar
app\_map (dict): Mapping of applications to integers.

\item {} 
\sphinxAtStartPar
uc\_map (dict): Mapping of use cases to integers.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} \begin{description}
\sphinxlineitem{tuple: A tuple containing:}\begin{itemize}
\item {} 
\sphinxAtStartPar
X\_scaled (np.ndarray): Scaled feature matrix.

\item {} 
\sphinxAtStartPar
X (pd.DataFrame): Original feature matrix.

\item {} 
\sphinxAtStartPar
y (pd.Series): Target variable.

\end{itemize}

\end{description}

\end{itemize}

\end{description}

\end{fulllineitems}

\index{random\_forest\_importance() (in module eda)@\spxentry{random\_forest\_importance()}\spxextra{in module eda}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{eda:eda.random_forest_importance}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{eda.}}\sphinxbfcode{\sphinxupquote{random\_forest\_importance}}}{\sphinxparam{\DUrole{n}{X\_scaled}}\sphinxparamcomma \sphinxparam{\DUrole{n}{X}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Train Random Forest and return feature importances.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
X\_scaled (np.ndarray): Scaled feature matrix.

\item {} 
\sphinxAtStartPar
X (pd.DataFrame): Original feature matrix.

\item {} 
\sphinxAtStartPar
y (pd.Series): Target variable.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
pd.Series: Feature importances sorted in descending order.

\item {} 
\sphinxAtStartPar
RandomForestClassifier: Trained Random Forest model.

\end{itemize}

\end{description}

\end{fulllineitems}

\index{rfe\_selection() (in module eda)@\spxentry{rfe\_selection()}\spxextra{in module eda}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{eda:eda.rfe_selection}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{eda.}}\sphinxbfcode{\sphinxupquote{rfe\_selection}}}{\sphinxparam{\DUrole{n}{X\_scaled}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y}}\sphinxparamcomma \sphinxparam{\DUrole{n}{X}}\sphinxparamcomma \sphinxparam{\DUrole{n}{rf}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Recursive Feature Elimination.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
X\_scaled (np.ndarray): Scaled feature matrix.

\item {} 
\sphinxAtStartPar
y (pd.Series): Target variable.

\item {} 
\sphinxAtStartPar
X (pd.DataFrame): Original feature matrix.

\item {} 
\sphinxAtStartPar
rf (RandomForestClassifier): Trained Random Forest model.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
pd.Series: Boolean mask indicating selected features.

\end{itemize}

\end{description}

\end{fulllineitems}

\index{rfecv\_selection() (in module eda)@\spxentry{rfecv\_selection()}\spxextra{in module eda}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{eda:eda.rfecv_selection}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{eda.}}\sphinxbfcode{\sphinxupquote{rfecv\_selection}}}{\sphinxparam{\DUrole{n}{X\_scaled}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y}}\sphinxparamcomma \sphinxparam{\DUrole{n}{X}}\sphinxparamcomma \sphinxparam{\DUrole{n}{rf}}}{}
\pysigstopsignatures
\sphinxAtStartPar
RFECV \sphinxhyphen{} RFE with cross\sphinxhyphen{}validation.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
X\_scaled (np.ndarray): Scaled feature matrix.

\item {} 
\sphinxAtStartPar
y (pd.Series): Target variable.

\item {} 
\sphinxAtStartPar
X (pd.DataFrame): Original feature matrix.

\item {} 
\sphinxAtStartPar
rf (RandomForestClassifier): Trained Random Forest model.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
pd.Series: Boolean mask indicating selected features.

\end{itemize}

\end{description}

\end{fulllineitems}

\index{sfs\_selection() (in module eda)@\spxentry{sfs\_selection()}\spxextra{in module eda}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{eda:eda.sfs_selection}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{eda.}}\sphinxbfcode{\sphinxupquote{sfs\_selection}}}{\sphinxparam{\DUrole{n}{X\_scaled}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y}}\sphinxparamcomma \sphinxparam{\DUrole{n}{X}}\sphinxparamcomma \sphinxparam{\DUrole{n}{rf}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Sequential Feature Selector.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
X\_scaled (np.ndarray): Scaled feature matrix.

\item {} 
\sphinxAtStartPar
y (pd.Series): Target variable.

\item {} 
\sphinxAtStartPar
X (pd.DataFrame): Original feature matrix.

\item {} 
\sphinxAtStartPar
rf (RandomForestClassifier): Trained Random Forest model.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
pd.Series: Boolean mask indicating selected features.

\end{itemize}

\end{description}

\end{fulllineitems}


\sphinxstepscope


\chapter{Label Real Dataset}
\label{\detokenize{add_current_uc:module-add_current_uc}}\label{\detokenize{add_current_uc:label-real-dataset}}\label{\detokenize{add_current_uc::doc}}\index{module@\spxentry{module}!add\_current\_uc@\spxentry{add\_current\_uc}}\index{add\_current\_uc@\spxentry{add\_current\_uc}!module@\spxentry{module}}\index{apply\_uc() (in module add\_current\_uc)@\spxentry{apply\_uc()}\spxextra{in module add\_current\_uc}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{add_current_uc:add_current_uc.apply_uc}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{add\_current\_uc.}}\sphinxbfcode{\sphinxupquote{apply\_uc}}}{\sphinxparam{\DUrole{n}{row}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Assign a Use Case (UC) label to a row based on its timestamp.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
row (pd.Series): A row with a ‘timestamp’ field.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
str: The UC label (‘uc1’ to ‘uc6’).

\end{itemize}

\end{description}

\end{fulllineitems}

\index{compare\_intervals() (in module add\_current\_uc)@\spxentry{compare\_intervals()}\spxextra{in module add\_current\_uc}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{add_current_uc:add_current_uc.compare_intervals}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{add\_current\_uc.}}\sphinxbfcode{\sphinxupquote{compare\_intervals}}}{\sphinxparam{\DUrole{n}{row}}\sphinxparamcomma \sphinxparam{\DUrole{n}{interval}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Compare a timestamp from a row with a given time interval.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
row (pd.Series): Row from the DataFrame with a ‘timestamp’ column.

\item {} 
\sphinxAtStartPar
interval (dict): Dictionary with “from” and “to” datetime strings.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
bool: True if timestamp is within interval, else False.

\end{itemize}

\end{description}

\end{fulllineitems}

\index{label\_realnetwork\_csv() (in module add\_current\_uc)@\spxentry{label\_realnetwork\_csv()}\spxextra{in module add\_current\_uc}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{add_current_uc:add_current_uc.label_realnetwork_csv}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{add\_current\_uc.}}\sphinxbfcode{\sphinxupquote{label\_realnetwork\_csv}}}{\sphinxparam{\DUrole{n}{input\_path}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}../datasets/real\_network\_data\_before\_labeling.csv\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{output\_path}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}../datasets/real\_network\_data\_after\_labeling.csv\textquotesingle{}}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Load the CSV, assign UC labels to each row, and save the updated file.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
input\_path (str): Path to the input CSV file.

\item {} 
\sphinxAtStartPar
output\_path (str): Path to save the labeled CSV file.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}


\sphinxstepscope


\chapter{Preprocess data for LSTM}
\label{\detokenize{lstm_preprocessing:module-lstm_preprocessing}}\label{\detokenize{lstm_preprocessing:preprocess-data-for-lstm}}\label{\detokenize{lstm_preprocessing::doc}}\index{module@\spxentry{module}!lstm\_preprocessing@\spxentry{lstm\_preprocessing}}\index{lstm\_preprocessing@\spxentry{lstm\_preprocessing}!module@\spxentry{module}}
\sphinxAtStartPar
Module for preparing LSTM input data from preprocessed features.
Includes functionality for loading feature arrays, creating sequences,
splitting the dataset, and saving the output for training and testing.

\sphinxAtStartPar
This module is intended for use with the Digital Twin of 5G Network project.
\index{create\_sequences() (in module lstm\_preprocessing)@\spxentry{create\_sequences()}\spxextra{in module lstm\_preprocessing}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_preprocessing:lstm_preprocessing.create_sequences}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{lstm\_preprocessing.}}\sphinxbfcode{\sphinxupquote{create\_sequences}}}{\sphinxparam{\DUrole{n}{X}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y}}\sphinxparamcomma \sphinxparam{\DUrole{n}{seq\_len}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Vytvorí sekvencie vstupných dát pre LSTM z kĺzavého okna.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{X}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} Vstupné dáta (features)

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} Cieľové hodnoty (triedy)

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{seq\_len}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Dĺžka sekvencie pre LSTM

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
(X\_seq, y\_seq) ako ndarray

\sphinxlineitem{Return type}
\sphinxAtStartPar
tuple

\end{description}\end{quote}

\end{fulllineitems}

\index{load\_data() (in module lstm\_preprocessing)@\spxentry{load\_data()}\spxextra{in module lstm\_preprocessing}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_preprocessing:lstm_preprocessing.load_data}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{lstm\_preprocessing.}}\sphinxbfcode{\sphinxupquote{load\_data}}}{\sphinxparam{\DUrole{n}{X\_path}}\sphinxparamcomma \sphinxparam{\DUrole{n}{Y\_path}}\sphinxparamcomma \sphinxparam{\DUrole{n}{scaler\_path}}\sphinxparamcomma \sphinxparam{\DUrole{n}{features\_path}}\sphinxparamcomma \sphinxparam{\DUrole{n}{uc\_map\_path}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Loads the preprocessed data from specified paths.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
X\_path (str): Path to the input features (X)

\item {} 
\sphinxAtStartPar
Y\_path (str): Path to the target labels (y)

\item {} 
\sphinxAtStartPar
scaler\_path (str): Path to the scaler object

\item {} 
\sphinxAtStartPar
features\_path (str): Path to the selected features JSON file

\item {} 
\sphinxAtStartPar
uc\_map\_path (str): Path to the UC map JSON file

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
tuple: (X, y, scaler, selected\_features, uc\_map)

\end{itemize}

\end{description}

\end{fulllineitems}

\index{split\_and\_save\_data() (in module lstm\_preprocessing)@\spxentry{split\_and\_save\_data()}\spxextra{in module lstm\_preprocessing}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{lstm_preprocessing:lstm_preprocessing.split_and_save_data}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{lstm\_preprocessing.}}\sphinxbfcode{\sphinxupquote{split\_and\_save\_data}}}{\sphinxparam{\DUrole{n}{X\_seq}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y\_seq}}\sphinxparamcomma \sphinxparam{\DUrole{n}{output\_dir}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}preprocessed\_data\textquotesingle{}}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Splits the dataset into training and testing sets and saves them to disk.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
X\_seq (np.ndarray): Input features in sequence format

\item {} 
\sphinxAtStartPar
y\_seq (np.ndarray): Target labels in sequence format

\item {} 
\sphinxAtStartPar
output\_dir (str): Directory to save the split data

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}


\sphinxstepscope


\chapter{Simulate a running network}
\label{\detokenize{running_network:module-running_network}}\label{\detokenize{running_network:simulate-a-running-network}}\label{\detokenize{running_network::doc}}\index{module@\spxentry{module}!running\_network@\spxentry{running\_network}}\index{running\_network@\spxentry{running\_network}!module@\spxentry{module}}\index{init\_log() (in module running\_network)@\spxentry{init\_log()}\spxextra{in module running\_network}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{running_network:running_network.init_log}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{running\_network.}}\sphinxbfcode{\sphinxupquote{init\_log}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Initializes the log file and directory if needed.
\begin{description}
\sphinxlineitem{Args}
\sphinxAtStartPar
None

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}

\index{run\_simulation() (in module running\_network)@\spxentry{run\_simulation()}\spxextra{in module running\_network}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{running_network:running_network.run_simulation}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{running\_network.}}\sphinxbfcode{\sphinxupquote{run\_simulation}}}{\sphinxparam{\DUrole{n}{script\_name}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Runs the selected UC simulation and logs its outcome.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
script\_name (str): Name of the UC script to run.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}


\sphinxstepscope


\chapter{Main orchestrator}
\label{\detokenize{network_watcher:module-network_watcher}}\label{\detokenize{network_watcher:main-orchestrator}}\label{\detokenize{network_watcher::doc}}\index{module@\spxentry{module}!network\_watcher@\spxentry{network\_watcher}}\index{network\_watcher@\spxentry{network\_watcher}!module@\spxentry{module}}\index{AttentionLayer (class in network\_watcher)@\spxentry{AttentionLayer}\spxextra{class in network\_watcher}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{network_watcher:network_watcher.AttentionLayer}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{network\_watcher.}}\sphinxbfcode{\sphinxupquote{AttentionLayer}}}{\sphinxparam{\DUrole{o}{*}\DUrole{n}{args}}\sphinxparamcomma \sphinxparam{\DUrole{o}{**}\DUrole{n}{kwargs}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Layer}}

\sphinxAtStartPar
Custom attention layer for LSTM model.
This layer computes the attention weights and applies them to the input sequence.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
Layer (tf.keras.layers.Layer): Base class for all layers in Keras.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}
\index{build() (network\_watcher.AttentionLayer method)@\spxentry{build()}\spxextra{network\_watcher.AttentionLayer method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{network_watcher:network_watcher.AttentionLayer.build}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{build}}}{\sphinxparam{\DUrole{n}{input\_shape}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Create the attention weights and bias.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
input\_shape (tuple): Shape of the input tensor.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}

\index{call() (network\_watcher.AttentionLayer method)@\spxentry{call()}\spxextra{network\_watcher.AttentionLayer method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{network_watcher:network_watcher.AttentionLayer.call}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{call}}}{\sphinxparam{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate the attention weights and apply them to the input sequence.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
x (tensor): Input tensor of shape (batch\_size, sequence\_length, features).

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
tensor: Output tensor of shape (batch\_size, features).

\end{itemize}

\end{description}

\end{fulllineitems}

\index{compute\_output\_shape() (network\_watcher.AttentionLayer method)@\spxentry{compute\_output\_shape()}\spxextra{network\_watcher.AttentionLayer method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{network_watcher:network_watcher.AttentionLayer.compute_output_shape}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{compute\_output\_shape}}}{\sphinxparam{\DUrole{n}{input\_shape}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the output shape of the layer.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
input\_shape (tuple): Shape of the input tensor.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
tuple: Shape of the output tensor.

\end{itemize}

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{clean\_old\_models() (in module network\_watcher)@\spxentry{clean\_old\_models()}\spxextra{in module network\_watcher}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{network_watcher:network_watcher.clean_old_models}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{network\_watcher.}}\sphinxbfcode{\sphinxupquote{clean\_old\_models}}}{\sphinxparam{\DUrole{n}{directory}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}/app/data/Model\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{keep\_last\_n}\DUrole{o}{=}\DUrole{default_value}{7}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pattern}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}Model\_bn\_*.keras\textquotesingle{}}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Keep only the last \sphinxtitleref{keep\_last\_n} saved model files and delete older ones.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
directory (str): Directory containing the model files.

\item {} 
\sphinxAtStartPar
keep\_last\_n (int): Number of recent models to keep.

\item {} 
\sphinxAtStartPar
pattern (str): Pattern to match model files.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}

\index{load\_last\_sequence() (in module network\_watcher)@\spxentry{load\_last\_sequence()}\spxextra{in module network\_watcher}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{network_watcher:network_watcher.load_last_sequence}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{network\_watcher.}}\sphinxbfcode{\sphinxupquote{load\_last\_sequence}}}{\sphinxparam{\DUrole{n}{csv\_path}}\sphinxparamcomma \sphinxparam{\DUrole{n}{selected\_features}}\sphinxparamcomma \sphinxparam{\DUrole{n}{sequence\_length}\DUrole{o}{=}\DUrole{default_value}{60}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Load the last sequence of records from CSV, ensuring all required features and labels are present.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
csv\_path (str): Path to the CSV file.

\item {} 
\sphinxAtStartPar
selected\_features (list): List of features to select from the DataFrame.

\item {} 
\sphinxAtStartPar
sequence\_length (int): Length of the sequence to load.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
tuple: DataFrame with selected features and the correct labels.

\end{itemize}

\sphinxlineitem{Raises}\begin{itemize}
\item {} 
\sphinxAtStartPar
ValueError: If any of the selected features are missing in the DataFrame.

\end{itemize}

\end{description}

\end{fulllineitems}

\index{main\_loop() (in module network\_watcher)@\spxentry{main\_loop()}\spxextra{in module network\_watcher}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{network_watcher:network_watcher.main_loop}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{network\_watcher.}}\sphinxbfcode{\sphinxupquote{main\_loop}}}{\sphinxparam{\DUrole{n}{interval}\DUrole{o}{=}\DUrole{default_value}{1}}\sphinxparamcomma \sphinxparam{\DUrole{n}{prometheus\_port}\DUrole{o}{=}\DUrole{default_value}{9000}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Main loop that monitors UE activity, parses logs, updates Prometheus metrics, and fine\sphinxhyphen{}tunes the model in real\sphinxhyphen{}time.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
interval (int): Time interval for monitoring and updating metrics.

\item {} 
\sphinxAtStartPar
prometheus\_port (int): Port for Prometheus metrics.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}

\index{parse\_amf() (in module network\_watcher)@\spxentry{parse\_amf()}\spxextra{in module network\_watcher}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{network_watcher:network_watcher.parse_amf}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{network\_watcher.}}\sphinxbfcode{\sphinxupquote{parse\_amf}}}{\sphinxparam{\DUrole{n}{lines}}\sphinxparamcomma \sphinxparam{\DUrole{n}{previous\_state}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Parse AMF log lines to extract UE registration and deregistration events,
update UE states, and compute registration/session durations.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
lines (list): List of log lines to parse.

\item {} 
\sphinxAtStartPar
previous\_state (dict): Previous state of UE details and durations.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
tuple: Updated UE details, new registration durations, and new session durations.

\end{itemize}

\end{description}

\end{fulllineitems}

\index{predict\_current\_uc() (in module network\_watcher)@\spxentry{predict\_current\_uc()}\spxextra{in module network\_watcher}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{network_watcher:network_watcher.predict_current_uc}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{network\_watcher.}}\sphinxbfcode{\sphinxupquote{predict\_current\_uc}}}{\sphinxparam{\DUrole{n}{latest\_window\_df}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Predict the current use case (UC) using the loaded LSTM model based on the latest data window.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
latest\_window\_df (pd.DataFrame): DataFrame containing the latest data window.

\end{itemize}

\sphinxlineitem{Returns}\begin{itemize}
\item {} 
\sphinxAtStartPar
tuple: Predicted UC class and confidence score.

\end{itemize}

\end{description}

\end{fulllineitems}

\index{remove\_offset() (in module network\_watcher)@\spxentry{remove\_offset()}\spxextra{in module network\_watcher}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{network_watcher:network_watcher.remove_offset}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{network\_watcher.}}\sphinxbfcode{\sphinxupquote{remove\_offset}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Remove the offset file used by Pygtail to start reading the log file from the beginning.
\begin{description}
\sphinxlineitem{Args}
\sphinxAtStartPar
None

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}

\index{run\_main\_notebook\_with\_backup() (in module network\_watcher)@\spxentry{run\_main\_notebook\_with\_backup()}\spxextra{in module network\_watcher}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{network_watcher:network_watcher.run_main_notebook_with_backup}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{network\_watcher.}}\sphinxbfcode{\sphinxupquote{run\_main\_notebook\_with\_backup}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Execute the main.ipynb notebook, log its execution, truncate CSV, and periodically create CSV backups.
\begin{description}
\sphinxlineitem{Args}
\sphinxAtStartPar
None

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}

\index{run\_notebook\_in\_thread() (in module network\_watcher)@\spxentry{run\_notebook\_in\_thread()}\spxextra{in module network\_watcher}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{network_watcher:network_watcher.run_notebook_in_thread}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{network\_watcher.}}\sphinxbfcode{\sphinxupquote{run\_notebook\_in\_thread}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Run the main.ipynb notebook in a separate thread to avoid blocking the main loop.
\begin{description}
\sphinxlineitem{Args}
\sphinxAtStartPar
None

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}

\index{save\_model\_with\_date() (in module network\_watcher)@\spxentry{save\_model\_with\_date()}\spxextra{in module network\_watcher}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{network_watcher:network_watcher.save_model_with_date}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{network\_watcher.}}\sphinxbfcode{\sphinxupquote{save\_model\_with\_date}}}{\sphinxparam{\DUrole{n}{model}}\sphinxparamcomma \sphinxparam{\DUrole{n}{path\_prefix}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}/app/data/Model/Model\_bn\_\textquotesingle{}}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Save the current model to disk with the current date as part of the filename.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
model (tf.keras.Model): The model to save.

\item {} 
\sphinxAtStartPar
path\_prefix (str): Prefix for the filename.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}

\index{truncate\_running\_data() (in module network\_watcher)@\spxentry{truncate\_running\_data()}\spxextra{in module network\_watcher}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{network_watcher:network_watcher.truncate_running_data}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{network\_watcher.}}\sphinxbfcode{\sphinxupquote{truncate\_running\_data}}}{\sphinxparam{\DUrole{n}{csv\_path}}\sphinxparamcomma \sphinxparam{\DUrole{n}{keep\_last\_n}\DUrole{o}{=}\DUrole{default_value}{60}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Truncate the CSV file to keep only the last \sphinxtitleref{keep\_last\_n} records.
\begin{description}
\sphinxlineitem{Args}\begin{itemize}
\item {} 
\sphinxAtStartPar
csv\_path (str): Path to the CSV file.

\item {} 
\sphinxAtStartPar
keep\_last\_n (int): Number of records to keep.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}

\end{fulllineitems}



\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{a}
\item\relax\sphinxstyleindexentry{add\_current\_uc}\sphinxstyleindexpageref{add_current_uc:\detokenize{module-add_current_uc}}
\indexspace
\bigletter{e}
\item\relax\sphinxstyleindexentry{eda}\sphinxstyleindexpageref{eda:\detokenize{module-eda}}
\indexspace
\bigletter{l}
\item\relax\sphinxstyleindexentry{lstm\_attention\_model}\sphinxstyleindexpageref{lstm_attention_model:\detokenize{module-lstm_attention_model}}
\item\relax\sphinxstyleindexentry{lstm\_base\_model}\sphinxstyleindexpageref{lstm_base_model:\detokenize{module-lstm_base_model}}
\item\relax\sphinxstyleindexentry{lstm\_bathnorm\_model}\sphinxstyleindexpageref{lstm_bathnorm_model:\detokenize{module-lstm_bathnorm_model}}
\item\relax\sphinxstyleindexentry{lstm\_preprocessing}\sphinxstyleindexpageref{lstm_preprocessing:\detokenize{module-lstm_preprocessing}}
\item\relax\sphinxstyleindexentry{lstm\_results\_real\_data}\sphinxstyleindexpageref{lstm_results_real_data:\detokenize{module-lstm_results_real_data}}
\item\relax\sphinxstyleindexentry{lstm\_robust\_model}\sphinxstyleindexpageref{lstm_robust_model:\detokenize{module-lstm_robust_model}}
\indexspace
\bigletter{n}
\item\relax\sphinxstyleindexentry{network\_watcher}\sphinxstyleindexpageref{network_watcher:\detokenize{module-network_watcher}}
\indexspace
\bigletter{r}
\item\relax\sphinxstyleindexentry{running\_network}\sphinxstyleindexpageref{running_network:\detokenize{module-running_network}}
\indexspace
\bigletter{u}
\item\relax\sphinxstyleindexentry{uc1}\sphinxstyleindexpageref{uc1:\detokenize{module-uc1}}
\item\relax\sphinxstyleindexentry{uc2}\sphinxstyleindexpageref{uc2:\detokenize{module-uc2}}
\item\relax\sphinxstyleindexentry{uc3}\sphinxstyleindexpageref{uc3:\detokenize{module-uc3}}
\item\relax\sphinxstyleindexentry{uc4}\sphinxstyleindexpageref{uc4:\detokenize{module-uc4}}
\item\relax\sphinxstyleindexentry{uc5}\sphinxstyleindexpageref{uc5:\detokenize{module-uc5}}
\item\relax\sphinxstyleindexentry{uc6}\sphinxstyleindexpageref{uc6:\detokenize{module-uc6}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}