{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tvorba datasetu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obsah<a class='anchor' id='top'></a>\n",
    "* [Globálne premenné](#globalne-premenne)\n",
    "* [Pripojenie na Prometheus](#pripojenie-na-prometheus)\n",
    "* [Časové vymedzenie](#casove-vymedzenie)\n",
    "* [Načítanie a spracovanie metrík z Prometheus](#nacitanie-a-spracovanie-metrik-z-prometheus)\n",
    "* [Spracovanie a extrakcia logov z funkcií Open5gs](#spracovanie-a-extrakcia-logov-z-funkcii-open5gs)\n",
    "* [Agregácia a transformácia dát](#agregacia-a-transformacia-dat)\n",
    "* [Triedenie logov](#triedenie-logov)\n",
    "* [Spojenie metrík a logov](#spojenie-metrik-a-logov)\n",
    "* [Mapovanie kategorických dát](#mapovanie-kategorickych-dat)\n",
    "* [Vloženie informácie o akutálnom UC](#vlozenie-informacie-o-akutalnom-uc)\n",
    "* [Uloženie datasetu](#ulozenie-datasetu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T12:00:42.297333Z",
     "iopub.status.busy": "2025-03-24T12:00:42.296921Z",
     "iopub.status.idle": "2025-03-24T12:00:42.503227Z",
     "shell.execute_reply": "2025-03-24T12:00:42.502967Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prometheus_api_client import PrometheusConnect\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import re\n",
    "import pytz\n",
    "from pathlib import Path\n",
    "import json\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"fivegs_smf\": [\n",
    "        \"fivegs_smffunction_sm_n4sessionreportsucc\",\n",
    "        \"fivegs_smffunction_sm_pdusessioncreationreq\",\n",
    "        \"fivegs_smffunction_sm_qos_flow_nbr\",\n",
    "    ],\n",
    "    \"fivegs_pcf\": [\n",
    "        \"fivegs_pcffunction_pa_policysmassosucc\",\n",
    "        \"fivegs_pcffunction_pa_sessionnbr\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globálne premenné\n",
    "PROMETHEUS_PORT = 9090                                                                            # Port for Prometheus metrics\n",
    "\n",
    "STEP = \"1s\"                                                                                       # Time step for the simulation\n",
    "TIMEDELTA_SECONDS = 10                                                                            # Time delta for the simulation\n",
    "LOCAL_TZ = pytz.timezone(\"Europe/Bratislava\")                                                     # TZ\n",
    "LOG_DIR = \"/open5gs/install/var/log/open5gs\"                                                                               # Directory with logs\n",
    "LOG_PATTERN = re.compile(r\"(\\d{2}/\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}):\\s+\\[(\\w+)\\]\\s+(\\w+):\\s*(.+)\")  # Regex pattern for log lines\n",
    "ENCODING = \"utf-8\"                                                                                # Encoding for log files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Príklad logu:</b> 04/02 11:05:03.836: [amf] INFO: [Added] Number of gNB-UEs is now 3 (../src/amf/context.c:2678)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T12:00:42.507419Z",
     "iopub.status.busy": "2025-03-24T12:00:42.507345Z",
     "iopub.status.idle": "2025-03-24T12:00:42.509272Z",
     "shell.execute_reply": "2025-03-24T12:00:42.509026Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vytvorenie spojenia s Prometheus serverom\n",
    "try:\n",
    "    prom = PrometheusConnect(url=f\"http://metrics:{PROMETHEUS_PORT}\", disable_ssl=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Prometheus: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Prometheus:</b> Pre správne fungovanie je potrebné sa uistiť, že Docker container 'metrics' je spustený a beží na porte 9090.<br>\n",
    "60f374bfb155   docker_metrics           \"/bin/bash -c /mnt/m…\"   2 days ago     Up 30 minutes   0.0.0.0:9090->9090/tcp   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Časový interval  \n",
    "end_time = datetime.now()\n",
    "start_time = end_time - timedelta(seconds=TIMEDELTA_SECONDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "\n",
    "# # Input range (UTC)\n",
    "# start_str = \"2025-04-14 12:52:30\"\n",
    "# end_str = \"2025-04-14 12:56:30\"\n",
    "\n",
    "# # Parse as UTC datetime\n",
    "# start_utc = datetime.fromisoformat(start_str)\n",
    "# end_utc = datetime.fromisoformat(end_str)\n",
    "\n",
    "# # Convert to local time with microseconds\n",
    "# start_local = start_utc.astimezone().replace(microsecond=0)\n",
    "# end_local = end_utc.astimezone().replace(microsecond=0)\n",
    "\n",
    "# print(\"Start time:\", start_utc)\n",
    "# print(\"End time:\", end_utc)\n",
    "\n",
    "# end_time = end_utc\n",
    "# start_time = start_utc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Načítanie a spracovanie metrík z Promethus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T12:00:42.526353Z",
     "iopub.status.busy": "2025-03-24T12:00:42.526276Z",
     "iopub.status.idle": "2025-03-24T12:00:42.664443Z",
     "shell.execute_reply": "2025-03-24T12:00:42.664179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No data: fivegs_smf/fivegs_smffunction_sm_pdusessioncreationreq\n",
      "⚠️ No data: fivegs_smf/fivegs_smffunction_sm_qos_flow_nbr\n",
      "⚠️ No data: fivegs_pcf/fivegs_pcffunction_pa_policysmassosucc\n",
      "⚠️ No data: fivegs_pcf/fivegs_pcffunction_pa_sessionnbr\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to hold metric DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Iterate through metric groups\n",
    "for group, metric_list in metrics.items():\n",
    "    for metric in metric_list:\n",
    "        try:\n",
    "            response = prom.custom_query_range(\n",
    "                metric, start_time=start_time, end_time=end_time, step=STEP\n",
    "            )\n",
    "\n",
    "            if not response:\n",
    "                print(f\"⚠️ No data: {group}/{metric}\")\n",
    "                continue\n",
    "\n",
    "            for entry in response:\n",
    "                base_metric_name = entry[\"metric\"].get(\"__name__\", metric)\n",
    "\n",
    "                if \"values\" in entry and isinstance(entry[\"values\"], list):\n",
    "                    extracted_values = [\n",
    "                        (\n",
    "                            datetime.utcfromtimestamp(int(ts))\n",
    "                            .replace(tzinfo=pytz.utc)\n",
    "                            .astimezone(LOCAL_TZ),\n",
    "                            float(val)\n",
    "                        )\n",
    "                        for ts, val in entry[\"values\"]\n",
    "                    ]\n",
    "\n",
    "                    metric_df = pd.DataFrame(extracted_values, columns=[\"timestamp\", \"value\"])\n",
    "                    metric_df[\"metric_name\"] = base_metric_name\n",
    "                    metric_df[\"group\"] = group\n",
    "\n",
    "                    df_list.append(metric_df)\n",
    "                else:\n",
    "                    print(f\"⚠️ No valid values found: {group}/{metric}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error fetching {group}/{metric}: {e}\")\n",
    "\n",
    "# Combine all metrics into one DataFrame\n",
    "if df_list:\n",
    "    final_df = pd.concat(df_list, ignore_index=True)\n",
    "    final_df['timestamp'] = final_df['timestamp'].astype(str).str.replace(r'\\+\\d{2}:\\d{2}', '', regex=True)\n",
    "    final_df[\"timestamp\"] = pd.to_datetime(final_df[\"timestamp\"])\n",
    "else:\n",
    "    print(\"❌ No data collected for any metric.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>final_df:</b> je dataframe, ktorý obsahuje všetky potrebné metriky z Prometheus.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spracovanie a extrakcia logov z funkcií Open5gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T12:00:42.728463Z",
     "iopub.status.busy": "2025-03-24T12:00:42.728390Z",
     "iopub.status.idle": "2025-03-24T12:00:42.834558Z",
     "shell.execute_reply": "2025-03-24T12:00:42.834244Z"
    }
   },
   "outputs": [],
   "source": [
    "log_data = []\n",
    "\n",
    "# Aplikácie, ktoré chceme sledovať\n",
    "allowed_applications = {\"amf\", \"upf\", \"smf\", \"udm\", \"gmm\"}\n",
    "\n",
    "for log_path in Path(LOG_DIR).glob(\"*.log\"):\n",
    "    try:\n",
    "        with open(log_path, \"r\", encoding=ENCODING, errors=\"ignore\") as f:\n",
    "            for line in f:\n",
    "                match = LOG_PATTERN.match(line)\n",
    "                if match:\n",
    "                    timestamp_str, application, log_level, log_message = match.groups()\n",
    "\n",
    "                    if application.lower() not in allowed_applications:\n",
    "                        continue\n",
    "\n",
    "                    # Konvertujeme timestamp na datetime\n",
    "                    log_timestamp = datetime.strptime(timestamp_str, \"%m/%d %H:%M:%S.%f\")\n",
    "                    log_timestamp = log_timestamp.replace(year=start_time.year, microsecond=0)\n",
    "\n",
    "                    # Nechávame len logy v časovom intervale\n",
    "                    if log_timestamp > start_time and log_timestamp < end_time:\n",
    "                        log_data.append({\n",
    "                            \"timestamp\": log_timestamp,\n",
    "                            \"application\": application,\n",
    "                            \"log_level\": log_level,\n",
    "                            \"log_message\": log_message\n",
    "                        })\n",
    "                    else:\n",
    "                        continue\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to process {log_path.name}: {e}\")\n",
    "\n",
    "log_data = pd.DataFrame(log_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>log_data:</b> je dataframe, ktorý obsahuje všetky potrebné logy z Open5gs.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agregácia a transformácia údajov o metrikách"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T12:00:42.880500Z",
     "iopub.status.busy": "2025-03-24T12:00:42.880428Z",
     "iopub.status.idle": "2025-03-24T12:00:42.889189Z",
     "shell.execute_reply": "2025-03-24T12:00:42.888966Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aggregácia dát z Prometheus metrík\n",
    "data_agg = final_df.groupby([\"timestamp\", \"metric_name\"])[\"value\"].mean().reset_index()\n",
    "data_pivot = data_agg.pivot(index=\"timestamp\", columns=\"metric_name\", values=\"value\")\n",
    "\n",
    "# Do názvov stĺpcov pridáme \"_value\"\n",
    "data_pivot.columns = [f\"{col}_value\" for col in data_pivot.columns]\n",
    "\n",
    "# Pridanie stĺpca s časom\n",
    "data_pivot.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_5G_csv = \"Model/real5g_scenarios1-5.csv\"\n",
    "# real_5G_df = pd.read_csv(real_5G_csv, sep=\",\", encoding=ENCODING)\n",
    "# real_5G_df[\"timestamp\"] = pd.to_datetime(real_5G_df[\"timestamp\"])\n",
    "\n",
    "# real_5G_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file = \"1_6.csv\"\n",
    "\n",
    "# # Determine whether to write header\n",
    "# write_header = not os.path.exists(csv_file) or os.path.getsize(csv_file) == 0\n",
    "\n",
    "# # Try filtering only new records if file exists and is not empty\n",
    "# if not write_header:\n",
    "#     try:\n",
    "#         last_timestamp = pd.read_csv(csv_file, usecols=[\"timestamp\"])[\"timestamp\"].max()\n",
    "#         data_pivot = data_pivot[data_pivot[\"timestamp\"] > last_timestamp]\n",
    "#     except Exception as e:\n",
    "#         print(f\"⚠️ Issue reading existing CSV: {e}. Proceeding without filtering.\")\n",
    "\n",
    "# # Append new data\n",
    "# if not data_pivot.empty:\n",
    "#     data_pivot.to_csv(csv_file, mode=\"a\", index=False, header=write_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T12:00:42.893116Z",
     "iopub.status.busy": "2025-03-24T12:00:42.893046Z",
     "iopub.status.idle": "2025-03-24T12:00:42.894955Z",
     "shell.execute_reply": "2025-03-24T12:00:42.894735Z"
    }
   },
   "outputs": [],
   "source": [
    "# Funkcia na klasifikáciu logov\n",
    "patterns = {\n",
    "    \"remove\": re.compile(r\"\\b(Removed|Deregister|De-register|Implicit De-registered)\\b\", re.IGNORECASE),\n",
    "    \"refused\": re.compile(r\"\\b(refused|connection refused)\\b\", re.IGNORECASE),\n",
    "    \"number_of_sessions_or_ues\": re.compile(r\"\\b(Number of (gNBs|AMF-UEs|AMF-Sessions|gNB-UEs))\\b\", re.IGNORECASE),\n",
    "    \"registration\": re.compile(r\"\\b(Registration request|InitialUEMessage|Added|Unknown UE by SUCI|SUCI)\\b\", re.IGNORECASE),\n",
    "    \"error\": re.compile(r\"\\b(ERROR)\\b\", re.IGNORECASE),\n",
    "    \"warning\": re.compile(r\"\\b(WARNING)\\b\", re.IGNORECASE),\n",
    "}\n",
    "\n",
    "def classify_log_message(message):\n",
    "    if not isinstance(message, str):\n",
    "        return \"nothing\"\n",
    "    for label, pattern in patterns.items():\n",
    "        if pattern.search(message):\n",
    "            return label\n",
    "    return \"nothing\"\n",
    "\n",
    "# Predtým ako pridáme stĺpec \"log_type\", skontrolujeme, či stĺpec \"log_message\" existuje\n",
    "if \"log_message\" in log_data.columns:\n",
    "\tlog_data[\"log_type\"] = log_data[\"log_message\"].apply(classify_log_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T12:00:42.901685Z",
     "iopub.status.busy": "2025-03-24T12:00:42.901613Z",
     "iopub.status.idle": "2025-03-24T12:00:42.903499Z",
     "shell.execute_reply": "2025-03-24T12:00:42.903288Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vytvoríme skrátenú verziu dát z logov\n",
    "logs_short = log_data[[\"timestamp\", \"application\", \"log_type\"]] \\\n",
    "\tif not log_data.empty \\\n",
    "\telse pd.DataFrame(columns=[\"timestamp\", \"application\", \"log_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T12:00:42.907731Z",
     "iopub.status.busy": "2025-03-24T12:00:42.907659Z",
     "iopub.status.idle": "2025-03-24T12:00:42.909949Z",
     "shell.execute_reply": "2025-03-24T12:00:42.909717Z"
    }
   },
   "outputs": [],
   "source": [
    "# Logy sú v UTC, takže ich lokalizujeme\n",
    "logs_short[\"timestamp\"] = pd.to_datetime(logs_short[\"timestamp\"], errors='coerce').dt.tz_localize(\"UTC\")\n",
    "\n",
    "# Filtrujeme logy podľa časového intervalu\n",
    "logs_short = logs_short[logs_short[\"timestamp\"] >= start_time.replace(tzinfo=pytz.utc)]\n",
    "\n",
    "# Odstránime časovú zónu z timestampu, aby sme mali rovnaký formát ako v Prometheus dátach\n",
    "logs_short[\"timestamp\"] = logs_short[\"timestamp\"].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplikáty odstránime na základe timestampu, aplikácie a typu logu\n",
    "logs_short = logs_short.drop_duplicates(subset=[\"timestamp\", \"application\", \"log_type\"])\n",
    "logs_short = logs_short.sort_values(by=[\"timestamp\", \"application\", \"log_type\"])\n",
    "logs_short = logs_short.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>logs_short:</b> tento dataframe budeme spájať s dataframe-om final_df.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_d = pd.merge(real_5G_df, logs_short, on=\"timestamp\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # drop the rows where the amf_session_value is Missing\n",
    "# merge_d = merge_d.dropna(subset=[\"amf_session_value\"])\n",
    "\n",
    "# merge_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metriky a logy spojíme na základe timestampu\n",
    "merged_data = pd.merge(data_pivot, logs_short, on=\"timestamp\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Missing metrics in final DataFrame:\n",
      "  - fivegs_pcffunction_pa_sessionnbr_value\n",
      "  - fivegs_pcffunction_pa_policysmassosucc_value\n",
      "  - fivegs_smffunction_sm_pdusessioncreationreq_value\n",
      "  - fivegs_smffunction_sm_qos_flow_nbr_value\n"
     ]
    }
   ],
   "source": [
    "featured_metrics = {\"features\": [\"fivegs_smffunction_sm_n4sessionreportsucc_value\", \"fivegs_pcffunction_pa_sessionnbr_value\", \"fivegs_pcffunction_pa_policysmassosucc_value\", \"fivegs_smffunction_sm_pdusessioncreationreq_value\", \"fivegs_smffunction_sm_qos_flow_nbr_value\", \"log_type\", \"application\"]}\n",
    "featured_metrics = featured_metrics[\"features\"]\n",
    "\n",
    "missing_metrics = []\n",
    "for metric in featured_metrics:\n",
    "    if metric not in merged_data.columns:\n",
    "        missing_metrics.append(metric)\n",
    "if missing_metrics:\n",
    "    print(\"❌ Missing metrics in final DataFrame:\")\n",
    "    for metric in missing_metrics:\n",
    "        print(f\"  - {metric}\")\n",
    "\n",
    "# Add columns for missing metrics\n",
    "for metric in missing_metrics:\n",
    "    merged_data[metric] = 0.0\n",
    "\n",
    "\n",
    "# Order the columns to match the selected features\n",
    "ordered_columns = [\"timestamp\"] + featured_metrics\n",
    "for col in merged_data.columns:\n",
    "    if col not in ordered_columns:\n",
    "        ordered_columns.append(col)\n",
    "merged_data = merged_data[ordered_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podľa preddefinovaných máp pre aplikácie a logy prevedieme hodnoty na číselné reprezentácie\n",
    "APP_MAP = {\"0\": 0, \"amf\": 1, \"gmm\": 2, \"udm\": 3, \"smf\": 4, \"upf\": 5}\n",
    "LOG_MAP = {\"0\": 0, \"registration\": 1, \"number_of_sessions_or_ues\": 2, \"nothing\": 3, \"remove\": 4, \"error\": 5}\n",
    "\n",
    "merged_data['application'] = merged_data['application'].map(APP_MAP).fillna(0)\n",
    "merged_data['log_type'] = merged_data['log_type'].map(LOG_MAP).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Mapovanie:</b> je potrebné zabezpečiť aby boli súbory 'app_map.json' a 'log_map.json' vytvorené a v správnom adresári.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_uc = None\n",
    "\n",
    "# Načítame aktuálny UC z textového súboru\n",
    "with open(\"./data/current_uc.txt\", \"r\") as f:\n",
    "    current_uc = f.read().strip()\n",
    "\n",
    "# Ak je aktuálny UC platný, pridáme ho do DataFrame\n",
    "if not merged_data.empty:\n",
    "    merged_data[\"current_uc\"] = current_uc\n",
    "\n",
    "UC_MAP = {\"uc1\": 0, \"uc2\": 1, \"uc3\": 2, \"uc4\": 3, \"uc5\": 4, \"uc6\": 5}\n",
    "\n",
    "# Prevedieme hodnoty v stĺpci \"current_uc\" na číselné reprezentácie\n",
    "merged_data['current_uc'] = merged_data['current_uc'].map(UC_MAP).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b> Mapovanie:</b> je potrebné zabezpečiť aby boli súbory 'uc_map.json' a 'current_uc.txt' vytvorené a v správnom adresári."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to csv\n",
    "# merged_data.to_csv(\"data_2.csv\", index=False, encoding=ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "fivegs_smffunction_sm_n4sessionreportsucc_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fivegs_pcffunction_pa_sessionnbr_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fivegs_pcffunction_pa_policysmassosucc_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fivegs_smffunction_sm_pdusessioncreationreq_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fivegs_smffunction_sm_qos_flow_nbr_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "log_type",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "application",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "current_uc",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "bc11e179-45ae-4c40-a631-639290736bb8",
       "rows": [
        [
         "0",
         "2025-04-24 22:58:41",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0"
        ],
        [
         "1",
         "2025-04-24 22:58:42",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0"
        ],
        [
         "2",
         "2025-04-24 22:58:43",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0"
        ],
        [
         "3",
         "2025-04-24 22:58:44",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0"
        ],
        [
         "4",
         "2025-04-24 22:58:45",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0"
        ],
        [
         "5",
         "2025-04-24 22:58:46",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0"
        ],
        [
         "6",
         "2025-04-24 22:58:47",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0"
        ],
        [
         "7",
         "2025-04-24 22:58:48",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0"
        ],
        [
         "8",
         "2025-04-24 22:58:49",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0"
        ],
        [
         "9",
         "2025-04-24 22:58:50",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0"
        ],
        [
         "10",
         "2025-04-24 22:58:51",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>fivegs_smffunction_sm_n4sessionreportsucc_value</th>\n",
       "      <th>fivegs_pcffunction_pa_sessionnbr_value</th>\n",
       "      <th>fivegs_pcffunction_pa_policysmassosucc_value</th>\n",
       "      <th>fivegs_smffunction_sm_pdusessioncreationreq_value</th>\n",
       "      <th>fivegs_smffunction_sm_qos_flow_nbr_value</th>\n",
       "      <th>log_type</th>\n",
       "      <th>application</th>\n",
       "      <th>current_uc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-24 22:58:41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-24 22:58:42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-24 22:58:43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-24 22:58:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-24 22:58:45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-04-24 22:58:46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-04-24 22:58:47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-04-24 22:58:48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-04-24 22:58:49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-04-24 22:58:50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-04-24 22:58:51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  fivegs_smffunction_sm_n4sessionreportsucc_value  \\\n",
       "0  2025-04-24 22:58:41                                              0.0   \n",
       "1  2025-04-24 22:58:42                                              0.0   \n",
       "2  2025-04-24 22:58:43                                              0.0   \n",
       "3  2025-04-24 22:58:44                                              0.0   \n",
       "4  2025-04-24 22:58:45                                              0.0   \n",
       "5  2025-04-24 22:58:46                                              0.0   \n",
       "6  2025-04-24 22:58:47                                              0.0   \n",
       "7  2025-04-24 22:58:48                                              0.0   \n",
       "8  2025-04-24 22:58:49                                              0.0   \n",
       "9  2025-04-24 22:58:50                                              0.0   \n",
       "10 2025-04-24 22:58:51                                              0.0   \n",
       "\n",
       "    fivegs_pcffunction_pa_sessionnbr_value  \\\n",
       "0                                      0.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      0.0   \n",
       "5                                      0.0   \n",
       "6                                      0.0   \n",
       "7                                      0.0   \n",
       "8                                      0.0   \n",
       "9                                      0.0   \n",
       "10                                     0.0   \n",
       "\n",
       "    fivegs_pcffunction_pa_policysmassosucc_value  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "5                                            0.0   \n",
       "6                                            0.0   \n",
       "7                                            0.0   \n",
       "8                                            0.0   \n",
       "9                                            0.0   \n",
       "10                                           0.0   \n",
       "\n",
       "    fivegs_smffunction_sm_pdusessioncreationreq_value  \\\n",
       "0                                                 0.0   \n",
       "1                                                 0.0   \n",
       "2                                                 0.0   \n",
       "3                                                 0.0   \n",
       "4                                                 0.0   \n",
       "5                                                 0.0   \n",
       "6                                                 0.0   \n",
       "7                                                 0.0   \n",
       "8                                                 0.0   \n",
       "9                                                 0.0   \n",
       "10                                                0.0   \n",
       "\n",
       "    fivegs_smffunction_sm_qos_flow_nbr_value  log_type  application  \\\n",
       "0                                        0.0       0.0          0.0   \n",
       "1                                        0.0       0.0          0.0   \n",
       "2                                        0.0       0.0          0.0   \n",
       "3                                        0.0       0.0          0.0   \n",
       "4                                        0.0       0.0          0.0   \n",
       "5                                        0.0       0.0          0.0   \n",
       "6                                        0.0       0.0          0.0   \n",
       "7                                        0.0       0.0          0.0   \n",
       "8                                        0.0       0.0          0.0   \n",
       "9                                        0.0       0.0          0.0   \n",
       "10                                       0.0       0.0          0.0   \n",
       "\n",
       "    current_uc  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "5            0  \n",
       "6            0  \n",
       "7            0  \n",
       "8            0  \n",
       "9            0  \n",
       "10           0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T12:00:42.929414Z",
     "iopub.status.busy": "2025-03-24T12:00:42.929343Z",
     "iopub.status.idle": "2025-03-24T12:00:42.933314Z",
     "shell.execute_reply": "2025-03-24T12:00:42.933111Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_file = \"./data/running_data.csv\"\n",
    "\n",
    "# Rozhodneme, či zapíšeme hlavičku\n",
    "write_header = not os.path.exists(csv_file) or os.path.getsize(csv_file) == 0\n",
    "\n",
    "# Pokúsime sa filtrovať iba nové záznamy, ak súbor existuje a nie je prázdny\n",
    "if not write_header:\n",
    "    try:\n",
    "        last_timestamp = pd.read_csv(csv_file, usecols=[\"timestamp\"])[\"timestamp\"].max()\n",
    "        merged_data = merged_data[merged_data[\"timestamp\"] > last_timestamp]\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Issue reading existing CSV: {e}. Proceeding without filtering.\")\n",
    "\n",
    "# Pridáme nové dáta\n",
    "if not merged_data.empty:\n",
    "    merged_data.to_csv(csv_file, mode=\"a\", index=False, header=write_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Uloženie datasetu:</b> je potrebné zabezpečiť aby bol súbor 'running_data.csv' vytvorený a v správnom adresári.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
